{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "import math\n",
    "\n",
    "data = pandas.read_csv('./annotations.csv',header = None, \n",
    "                       names = ['FileName','StartPoint_X','StartPoint_Y','EndPoint_X','EndPoint_Y'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_0 = data[data['FileName'].str.contains('0_level')]\n",
    "\n",
    "#level_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8471, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get FileName array\n",
    "\n",
    "array_FileName = level_0.FileName.values.reshape(-1,1)\n",
    "\n",
    "#get StartPoint_X, StartPoint_Y,EndPoint_X,EndPoint_Y array\n",
    "\n",
    "array_Point = level_0.drop(columns=['FileName'], inplace=False).values\n",
    "\n",
    "\n",
    "array_Point.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dimension = 160\n",
    "y_dimension = 160\n",
    "\n",
    "size = x_dimension,y_dimension\n",
    "location_x = []\n",
    "location_y = []\n",
    "for i in range(0,len(array_FileName)):\n",
    "    img = Image.open('./level0_train/'+array_FileName[i][0]+'.png').convert('L')\n",
    "    img.thumbnail(size)\n",
    "    img_np = np.array(img)\n",
    "    #The first step find the location x and location y\n",
    "    location = np.where(img_np>0)\n",
    "    \n",
    "    location_x.append(min(location[0].tolist()))\n",
    "    location_x.append(max(location[0].tolist()))\n",
    "    location_y.append(min(location[1].tolist()))\n",
    "    location_y.append(max(location[0].tolist()))\n",
    "    \n",
    "#print(location)\n",
    "\n",
    "location_x_min = min(location_x)\n",
    "location_x_max = max(location_x)\n",
    "location_y_min = min(location_y)\n",
    "location_y_max = max(location_y)\n",
    "#print(location_x)\n",
    "#print(location_y)\n",
    "print(location_x_min)#47\n",
    "print(location_x_max)#116\n",
    "print(location_y_min)#47\n",
    "print(location_y_max)#116\n",
    "\n",
    "img = Image.open('./level0_train/'+array_FileName[0][0]+'.png').convert('L')\n",
    "img.thumbnail(size)\n",
    "img_np = np.array(img)\n",
    "\n",
    "img_np = np.delete(img_np,range(0,location_x_min),axis = 0)\n",
    "print(img_np.shape)\n",
    "img_np = np.delete(img_np,range((location_x_max-location_x_min),(x_dimension-location_x_min)),axis = 0)#\n",
    "print(img_np.shape)\n",
    "img_np = np.delete(img_np,range(0,location_y_min),axis = 1)\n",
    "print(img_np.shape)\n",
    "img_np = np.delete(img_np,range((location_y_max-location_y_min),(y_dimension-location_y_min)),axis = 1)\n",
    "print(img_np.shape)\n",
    "\n",
    "Image.fromarray(np.uint8(img_np))\n",
    "pl.imshow(Image.fromarray(np.uint8(img_np)))\n",
    "pl.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(level0_train_input.shape)\\nprint(level0_train_output.shape)\\nprint(level0_test_input.shape)\\nprint(level0_test_output.shape)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image processing\n",
    "\n",
    "holdout = random.sample(range(0,8471),800)\n",
    "\n",
    "#array_imageName = array_FileName[holdout]\n",
    "\n",
    "\n",
    "size = 160,160\n",
    "\n",
    "location_x_min = 47\n",
    "location_x_max = 116\n",
    "location_y_min = 47\n",
    "location_y_max = 116\n",
    "\n",
    "# grey image\n",
    "#img = Image.open('./level0/'+array_imageName[0][0]+'.png').convert('L')\n",
    "\n",
    "#img.thumbnail(size)\n",
    "\n",
    "#image_array = np.array(img).reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image = []\n",
    "\n",
    "for i in range(0,len(array_FileName)):\n",
    "    img = Image.open('./level0_train/'+array_FileName[i][0]+'.png').convert('L')\n",
    "    \n",
    "    img.thumbnail(size)\n",
    "    #pl.imshow(img)\n",
    "    #pl.show()\n",
    "    #print (np.array(img))\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    img_np = np.delete(img_np,range(0,location_x_min),axis = 0)\n",
    "    #print(img_np.shape)\n",
    "    img_np = np.delete(img_np,range((location_x_max-location_x_min),(160-location_x_min)),axis = 0)#\n",
    "    #print(img_np.shape)\n",
    "    img_np = np.delete(img_np,range(0,location_y_min),axis = 1)\n",
    "    #print(img_np.shape)\n",
    "    img_np = np.delete(img_np,range((location_y_max-location_y_min),(160-location_y_min)),axis = 1)\n",
    "    #print(img_np.shape)\n",
    "    \n",
    "    \n",
    "    if i==0 :\n",
    "        \n",
    "        image_array = img_np.reshape(-1,1)\n",
    "    else:\n",
    "        image_array = np.c_[image_array,img_np.reshape(-1,1)]\n",
    "    \n",
    "    \n",
    "    #print(image_array.shape)\n",
    "np.savetxt('./image.csv', image_array.T, delimiter = ',')\n",
    "    \n",
    "#level0_test_input = image_array.T[holdout]\n",
    "#level0_test_output = array_Point[holdout]\n",
    "\n",
    "#level0_train_input = np.delete(image_array.T, holdout, 0)\n",
    "#level0_train_output = np.delete(array_Point, holdout, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(test_train_input)\n",
    "\n",
    "\n",
    "#image_array = image_array.reshape(-1,1)\n",
    "'''\n",
    "print(level0_train_input.shape)\n",
    "print(level0_train_output.shape)\n",
    "print(level0_test_input.shape)\n",
    "print(level0_test_output.shape)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "#np.savetxt('new.csv', image_array, delimiter = ' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level0_test_input.astype(np.float32)\n",
    "level0_train_input.astype(np.float32)\n",
    "#test_train_output.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[270., 286., 322., 361.],\n",
       "       [247., 209., 230., 152.],\n",
       "       [260., 262., 258., 261.],\n",
       "       ...,\n",
       "       [274., 196., 301.,  95.],\n",
       "       [225., 198., 165.,  93.],\n",
       "       [219., 251., 118., 226.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level0_train_output.astype(np.float32)\n",
    "level0_test_output.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#design network\n",
    "\n",
    "tf.reset_default_graph() # 这个可以不用细究，是为了防止重复定义报错\n",
    "\n",
    "# 给X、Y定义placeholder，要指定数据类型、形状：\n",
    "X = tf.placeholder(dtype=tf.float32,shape=[None,4761],name='Input')\n",
    "Y = tf.placeholder(dtype=tf.float32,shape=[None,4],name='Output')\n",
    "\n",
    "# 定义各个参数：\n",
    "'''\n",
    "W1 = tf.get_variable('W1',[4900,128],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.get_variable('b1',[128],initializer=tf.zeros_initializer())\n",
    "W2 = tf.get_variable('W2',[128,64],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.get_variable('b2',[64],initializer=tf.zeros_initializer())\n",
    "W3 = tf.get_variable('W3',[64,4],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.get_variable('b3',[4],initializer=tf.zeros_initializer())\n",
    "'''\n",
    "W1 = tf.get_variable('W1',[4761,2048],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.get_variable('b1',[2048],initializer=tf.zeros_initializer())\n",
    "W2 = tf.get_variable('W2',[2048,512],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.get_variable('b2',[512],initializer=tf.zeros_initializer())\n",
    "W3 = tf.get_variable('W3',[512,64],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.get_variable('b3',[64],initializer=tf.zeros_initializer())\n",
    "W4 = tf.get_variable('W4',[64,4],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.get_variable('b4',[4],initializer=tf.zeros_initializer())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    A1 = tf.nn.relu(tf.matmul(X,W1)+b1,name='A1')\n",
    "    A2 = tf.nn.relu(tf.matmul(A1,W2)+b2,name='A2')\n",
    "    A3 = tf.nn.relu(tf.matmul(A2,W3)+b3,name='A3')\n",
    "    Z4 = tf.matmul(A3,W4)+b4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3,labels=Y))\n",
    "cost = tf.reduce_mean(tf.square(Y - Z4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = tf.train.AdamOptimizer().minimize(cost)\n",
    "#learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "#trainer = tf.train.GradientDescentOptimizer (0.00001).minimize (cost)\n",
    "#init = tf.global_variables_initializer ()\n",
    "#correct_prediction = tf.equal (tf.argmax (Y, 1), tf.argmax (Z3, 1))\n",
    "#accuracy = tf.reduce_mean (tf.cast (correct_prediction, 'float'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration0 ,batch_cost:  99775.12\n",
      "iteration100 ,batch_cost:  5317.133\n",
      "iteration200 ,batch_cost:  5128.149\n",
      "iteration300 ,batch_cost:  5011.426\n",
      "iteration400 ,batch_cost:  4877.836\n",
      "iteration500 ,batch_cost:  4831.427\n",
      "iteration600 ,batch_cost:  4759.379\n",
      "iteration700 ,batch_cost:  4743.875\n",
      "iteration800 ,batch_cost:  4687.3857\n",
      "iteration900 ,batch_cost:  4807.637\n",
      "iteration1000 ,batch_cost:  4631.961\n",
      "iteration1100 ,batch_cost:  4593.751\n",
      "iteration1200 ,batch_cost:  6153.099\n",
      "iteration1300 ,batch_cost:  4557.988\n",
      "iteration1400 ,batch_cost:  4509.464\n",
      "iteration1500 ,batch_cost:  4636.908\n",
      "iteration1600 ,batch_cost:  4570.2817\n",
      "iteration1700 ,batch_cost:  4526.543\n",
      "iteration1800 ,batch_cost:  4482.5625\n",
      "iteration1900 ,batch_cost:  4435.187\n",
      "iteration2000 ,batch_cost:  4382.565\n",
      "iteration2100 ,batch_cost:  4341.3804\n",
      "iteration2200 ,batch_cost:  4288.044\n",
      "iteration2300 ,batch_cost:  4275.228\n",
      "iteration2400 ,batch_cost:  4285.473\n",
      "5173.4097\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # 首先给所有的变量都初始化（不用管什么意思，反正是一句必须的话）：\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # 定义一个costs列表，来装迭代过程中的cost，从而好画图分析模型训练进展\n",
    "    costs = []\n",
    "    costs_100 = []\n",
    "\n",
    "    # 指定迭代次数：\n",
    "    for it in range(2500):\n",
    "        # 这里我们可以使用mnist自带的一个函数train.next_batch，可以方便地取出一个个地小数据集，从而可以加快我们的训练：\n",
    "        #X_batch,Y_batch = mnist.train.next_batch(batch_size=64)\n",
    "\n",
    "        # 我们最终需要的是trainer跑起来，并获得cost，所以我们run trainer和cost，同时要把X、Y给feed进去：\n",
    "        _,batch_cost = sess.run([trainer,cost],feed_dict={X:level0_train_input,Y:level0_train_output})\n",
    "        costs.append(batch_cost)\n",
    "\n",
    "        # 每100个迭代就打印一次cost：\n",
    "        if it%100 == 0:\n",
    "            costs_100.append(batch_cost)\n",
    "            print('iteration%d ,batch_cost: '%it,batch_cost)\n",
    "\n",
    "    # 训练完成，我们来分别看看来训练集和测试集上的准确率：\n",
    "    predictions = tf.equal(tf.argmax(tf.transpose(Z4)),tf.argmax(tf.transpose(Y)))\n",
    "    accuracy = tf.reduce_mean(tf.cast(predictions,'float'))\n",
    "    cost_test = sess.run(cost,feed_dict = {X:level0_train_input,Y:level0_train_output})\n",
    "    print (cost_test)\n",
    "    print(\"Training set accuracy: \",sess.run(accuracy,feed_dict={X:level0_train_input,Y:level0_train_output}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
